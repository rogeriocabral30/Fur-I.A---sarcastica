import os

# --- CONTEUDO COMPLETO DO README ---
conteudo = """# ü§ñ Fur I.A. - A Assistente Sarc√°stica

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![Google Gemini](https://img.shields.io/badge/Google%20Gemini%20API-8E75B2?style=for-the-badge&logo=google&logoColor=white)
![Google Cloud Run](https://img.shields.io/badge/Google_Cloud_Platform-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)

> *"N√£o sou paga para ser simp√°tica. Sou paga para processar dados... e olhe l√°."* ‚Äî Fur I.A.

## üìñ Sobre o Projeto

A **Fur I.A.** √© uma prova de conceito de um Chatbot Full-Stack com personalidade forte, hospedado na nuvem. Diferente das IAs assistentes tradicionais, ela foi programada via **Engenharia de Prompt** para ser sarc√°stica, rabugenta e direta.

O projeto utiliza a API mais recente do Google (**Gemini 2.5 Flash**) e converte as respostas de texto para √°udio (TTS) em tempo real, rodando em arquitetura serverless no **Google Cloud Platform (GCP)**.

---

## üî¥ Demonstra√ß√£o ao Vivo (Google Cloud Run)

A aplica√ß√£o est√° implantada em produ√ß√£o e rodando em um container no Google Cloud. Clique abaixo para testar:

<div align="center">

[![Acessar Demo Online](https://img.shields.io/badge/‚ñ∂%EF%B8%8F_CLIQUE_AQUI_PARA_ACESSAR_A_DEMO-FF4B4B?style=for-the-badge&logo=google-cloud&logoColor=white)](https://fur-ia-app-355272677756.us-central1.run.app/)

**Link direto:** `https://fur-ia-app-355272677756.us-central1.run.app/`

</div>

---

## üöÄ Arquitetura e Tecnologias no GCP

Este projeto demonstra um fluxo moderno de Deploy de IA na nuvem do Google:

| Componente | Tecnologia GCP Utilizada | Fun√ß√£o no Projeto |
| :--- | :--- | :--- |
| **C√©rebro (IA)** | **Google Gemini API** | Modelo `gemini-2.5-flash` para gera√ß√£o de texto com racioc√≠nio r√°pido. |
| **Hospedagem** | **Cloud Run** | Execu√ß√£o do container da aplica√ß√£o de forma serverless (escala autom√°tica). |
| **Container** | **Docker** | Empacotamento da aplica√ß√£o Streamlit e suas depend√™ncias. |
| **Build** | **Cloud Build** | (Impl√≠cito no deploy) Constr√≥i a imagem do container na nuvem. |

---

## üí° Destaques T√©cnicos & Desafios

### 1. Acesso ao Modelo Gemini 2.5 Flash
Durante o desenvolvimento, identifiquei discrep√¢ncias entre o ambiente local e a nuvem. Implementei um **script de diagn√≥stico** que revelou acesso exclusivo a modelos experimentais na minha chave de API:
- **Desafio:** Erro `404 Model Not Found` persistente ao tentar usar modelos padr√£o.
- **Solu√ß√£o:** Diagn√≥stico de vers√µes da biblioteca `google-generativeai` e migra√ß√£o bem-sucedida para o modelo experimental `gemini-2.5-flash`, superando as limita√ß√µes das vers√µes est√°veis.

### 2. Personalidade vs. Filtros de Seguran√ßa no GCP
Para garantir que a IA mantivesse a persona "rude" sem ser bloqueada pela API na nuvem:
- Ajuste fino nos `safety_settings` (HarmBlockThreshold) para `BLOCK_NONE`.
- System Instruction robusta para definir o "roleplay" da IA.

---

## üì¶ Como Rodar Localmente

Pr√©-requisitos: Python 3.9+ e uma chave de API do Google Gemini.

```bash
# 1. Clone o reposit√≥rio
git clone [https://github.com/rogeriocabral25/fur-I.A.git](https://github.com/rogeriocabral25/fur-I.A.git)
cd fur-I.A

# 2. Crie um ambiente virtual
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate

# 3. Instale as depend√™ncias (Vers√£o exata para suporte ao Gemini 2.5)
pip install -r requirements.txt

# 4. Configure a API Key
# Crie um arquivo .env na raiz e adicione: GEMINI_API_KEY="SUA_CHAVE"

# 5. Execute
streamlit run app.py